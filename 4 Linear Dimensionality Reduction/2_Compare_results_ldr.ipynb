{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying PCA to a Dataset Using scikit-learn\n",
    "\n",
    "### Objective\n",
    "Gain practical experience in applying PCA using Python.\n",
    "\n",
    "### Content\n",
    "- Introduction to the scikit-learn library for PCA\n",
    "- Loading a dataset (e.g., Iris dataset)\n",
    "- Performing PCA with scikit-learn\n",
    "- Visualizing the principal components using matplotlib or seaborn\n",
    "\n",
    "### Instructions\n",
    "To get the maximum value from the exercise, start with the empty notebook, and try to solve the exercises by relying only on what you've learned. Then, if you're really stuck, go to the filled notebook to see proposed solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the necessary libraries\n",
    "We will use `numpy`, `pandas`, `scikit-learn`, `matplotlib`, and `seaborn` for this activity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the dataset\n",
    "We will use the Iris dataset, which is a classic dataset in machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Standardize the data\n",
    "PCA is affected by the scale of the data, so we need to standardize it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = iris.feature_names\n",
    "x = df.loc[:, features].values\n",
    "x = StandardScaler().fit_transform(x)\n",
    "df_standardized = pd.DataFrame(x, columns=features)\n",
    "df_standardized['target'] = df['target']\n",
    "df_standardized.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Perform PCA\n",
    "We will perform PCA to reduce the dimensionality of the dataset to 2 components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(x)\n",
    "df_pca = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "df_pca['target'] = df['target']\n",
    "df_pca.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize the principal components\n",
    "We will use a scatter plot to visualize the principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='target', data=df_pca, palette='Set1')\n",
    "plt.title('PCA of Iris Dataset')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
